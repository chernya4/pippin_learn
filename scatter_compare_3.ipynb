{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64b1cd07",
   "metadata": {},
   "source": [
    "### GENMODEL_MSKOPT and Why We Must Modify the Code ###\n",
    "\n",
    "The data analysed in the `scatter_compare_2.ipynb` was the following folders:\n",
    "\n",
    "- `MC_BAYSN_NOSCATTER`\n",
    "- `MC_BAYSN_PLUSSCATTER`\n",
    "\n",
    "The results in `scatter_compare_2.ipynb` included a coherent component, making the scatter ~ 0.12mag. It should be ~ 0.1mag.\n",
    "\n",
    "After consluting with Stephen Thorp and Matt Greyling, we ended up changing the scatter simulation to `GENMODEL_MSKOPT: 2` for the scatter and kept `GENMODEL_MSKOPT: 0`. For the no scatter. \n",
    "\n",
    "<h3><u>From the SNANA manual BEYSN MASKOPT feature: </u></h3>\n",
    "\n",
    "\n",
    "\n",
    "**References**:  \n",
    "K. S. Mandel et al., *MNRAS* **510**, 3939 (2022);  \n",
    "S. Thorp et al., *MNRAS* **508**, 4310 (2021);  \n",
    "M. Grayling et al., *MNRAS* **531**, 953 (2024).  \n",
    "[3, 33, 34].\n",
    "\n",
    "Note that host-galaxy extinction parameters (for $A_V, R_V$) are required from §9.1. The form of the host-galaxy dust extinction curve will be inherited from the Milky Way color law. Only $begin:math:text$R_V$end:math:text$-dependent extinction curves are currently supported (§4.21.2).\n",
    "\n",
    "**Simulation input keys for `snlc_sim.exe`**:\n",
    "```yaml\n",
    "GENMEAN_THETA: xxx         # shape parameter\n",
    "GENRANGE_THETA: xxx xxx\n",
    "GENSIGMA_THETA: xxx xxx\n",
    "GENMODEL_MSKOPT: <mask>    # additional settings\n",
    "```\n",
    "\n",
    "The additional settings that can be enabled via setting bits in `GENMODEL_MSKOPT` are as follows:\n",
    "\n",
    "- `GENMODEL_MSKOPT += 1`: Enable BayeSN’s default (recommended) residual scatter model. Includes a gray component,  \n",
    "  $\\delta M \\sim \\mathcal{N}(0, \\sigma_0^2)$, and a time- and wavelength-dependent component,  \n",
    "  $\\epsilon \\sim \\mathcal{N}(0, \\Sigma_\\epsilon)$.  \n",
    "  The (co)variance of these components is set by the YAML file defining the version of the BayeSN `GENMODEL` specified in the sim input.\n",
    "\n",
    "- `GENMODEL_MSKOPT += 2`: Enable the non-gray ($\\epsilon$) component of the BayeSN residual scatter model.\n",
    "\n",
    "- `GENMODEL_MSKOPT += 4`: Enable the gray ($\\delta M$) component of the BayeSN residual scatter model.\n",
    "\n",
    "- `GENMODEL_MSKOPT += 128`: Enable a “verbose” mode for debugging purposes.\n",
    "\n",
    "> Multiple bits can be combined, when this is unambiguous.  \n",
    "> For example, `GENMODEL_MSKOPT=6` would enable both components of the residual scatter model (equivalent to `GENMODEL_MSKOPT=1`).  \n",
    "> An ambiguous combination of bits will cause the program to abort.\n",
    "\n",
    "<h3><u>New Data Being Analyzed in this notebook: </u></h3>\n",
    "\n",
    "The data analysed in the `scatter_compare_2.ipynb` was the following folders:\n",
    "\n",
    "- `MYC21_07222025_DESC_SIM_NOSCATTER`\n",
    "- `MYC21_07222025_DESC_SIM_PLUSSCATTER`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "013da3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbffca81",
   "metadata": {},
   "source": [
    "### Rewriting the PeakMJD Code to Eliminate the Necessity for getting Rid of Mismatches ###\n",
    "\n",
    "In the notebook titled `scatter_compare_2.ipynb`, we were using the `PEAKMJD` entry of the individual data file which computed the Peak Modified Julian Date. There is also the `SIM_PEAKMJD` entry.\n",
    "\n",
    "`PEAKMJD` was inconsistent between data sets which caused the +/- 7 day range around it to be inconsistent between the scatter and noscatter .DAT files. \n",
    "\n",
    "To fix this we will use `SIM_PEAKMJD` which is consistent between data sets and will eliminate the need to filter out rows that do not match the MJD values between the scatter and no scatter datasets. \n",
    "\n",
    "The main modification in the below code is switching `PEAKMJD` to `SIM_PEAKMJD` in the collect_near_peak_rows() method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "30dc04e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_near_peak_rows(folder_path):\n",
    "    \"\"\"\n",
    "    Collects all near-peak (±7 days) rows from all .DAT files in a folder.\n",
    "    Returns a DataFrame with all VARLIST columns + FILENAME.\n",
    "    \"\"\"\n",
    "\n",
    "    # Empty list to store all rows from all files\n",
    "    all_rows = []\n",
    "\n",
    "    # Loops through each file in the specified folder\n",
    "    # and builds path to each .DAT file\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".DAT\"):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "\n",
    "            # --- Extract PEAKMJD ---\n",
    "            peak_mjd = None  # Empty variable to store PEAKMJD\n",
    "            with open(file_path, \"r\") as f:\n",
    "                for line in f:\n",
    "                    if \"SIM_PEAKMJD\" in line:\n",
    "                        parts = line.strip().replace(\":\", \"\").split()\n",
    "                        peak_mjd = float(parts[parts.index(\"SIM_PEAKMJD\") + 1])\n",
    "                        break\n",
    "\n",
    "            # --- Extract OBS rows and filter by ±7 days ---\n",
    "            with open(file_path, \"r\") as f:\n",
    "                for line in f:\n",
    "                    if line.startswith(\"OBS:\"):\n",
    "                        parts = line.strip().split()\n",
    "                        mjd = float(parts[1])\n",
    "                        band = parts[2]\n",
    "                        field = parts[3]\n",
    "                        fluxcal = float(parts[4])\n",
    "                        fluxcalerr = float(parts[5])\n",
    "                        photflag = int(parts[6])\n",
    "                        gain = float(parts[7])\n",
    "                        zpt = float(parts[8])\n",
    "                        psf = float(parts[9])\n",
    "                        sky_sig = float(parts[10])\n",
    "                        sim_magobs = float(parts[11])\n",
    "\n",
    "                        ## all_rows built up sequentially as we read each line.\n",
    "                        if abs(mjd - peak_mjd) <= 7:\n",
    "                            all_rows.append((\n",
    "                                filename, mjd, band, field, fluxcal, fluxcalerr,\n",
    "                                photflag, gain, zpt, psf, sky_sig, sim_magobs\n",
    "                            ))\n",
    "\n",
    "    return pd.DataFrame(\n",
    "        all_rows,\n",
    "        columns=[\n",
    "            \"FILENAME\", \"MJD\", \"BAND\", \"FIELD\", \"FLUXCAL\", \"FLUXCALERR\",\n",
    "            \"PHOTFLAG\", \"GAIN\", \"ZPT\", \"PSF\", \"SKY_SIG\", \"SIM_MAGOBS\"\n",
    "        ]\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d667e6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOSCATTER near-peak rows: 367\n",
      "PLUSSCATTER near-peak rows: 367\n",
      "NOSCATTER data saved to nos_near_peak_rows.csv\n",
      "PLUSSCATTER data saved to plus_near_peak_rows.csv\n"
     ]
    }
   ],
   "source": [
    "# --- STEP 1: Collect rows from both folders ---\n",
    "nos_folder = \"/Users/pittsburghgraduatestudent/repos/pippin_learn/MYC21_07222025_DESC_SIM_NOSCATTER\"\n",
    "plus_folder = \"/Users/pittsburghgraduatestudent/repos/pippin_learn/MYC21_07222025_DESC_SIM_PLUSSCATTER\"\n",
    "\n",
    "nos_df = collect_near_peak_rows(nos_folder)\n",
    "plus_df = collect_near_peak_rows(plus_folder)\n",
    "\n",
    "print(f\"NOSCATTER near-peak rows: {len(nos_df)}\")\n",
    "print(f\"PLUSSCATTER near-peak rows: {len(plus_df)}\")\n",
    "\n",
    "nos_df.to_csv(\"nos_near_peak_rows.csv\", index=False)\n",
    "plus_df.to_csv(\"plus_near_peak_rows.csv\", index=False)\n",
    "\n",
    "print(\"NOSCATTER data saved to nos_near_peak_rows.csv\")\n",
    "print(\"PLUSSCATTER data saved to plus_near_peak_rows.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ec01ea",
   "metadata": {},
   "source": [
    "### Merge the PLUSSCATTER entries and NOSCATTER Entries into 1 .CSV ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a6cd306e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged data saved to merged_near_peak_rows_n_d.csv\n"
     ]
    }
   ],
   "source": [
    "# extracts the SN identifier from FILENAME\n",
    "# SN - literal text match\n",
    "# \\d+ - matches one or more digits after the SN\n",
    "# () - captures only this group and no other file name. \n",
    "\n",
    "nos_df[\"FILENAME\"] = nos_df[\"FILENAME\"].str.extract(r\"(SN\\d+)\")\n",
    "plus_df[\"FILENAME\"] = plus_df[\"FILENAME\"].str.extract(r\"(SN\\d+)\")\n",
    "\n",
    "merged_df = pd.merge(\n",
    "    nos_df,\n",
    "    plus_df,\n",
    "    on=[\"FILENAME\", \"MJD\", \"BAND\"],\n",
    "    suffixes=(\"_NO_S\", \"_PLUS_S\"),\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "merged_df.to_csv(\"merged_near_peak_rows_n_d.csv\", index=False)\n",
    "print(\"Merged data saved to merged_near_peak_rows_n_d.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155271f5",
   "metadata": {},
   "source": [
    "### Check if there area any mismatches ###\n",
    "\n",
    "Good way to test and see if the code is working propperly. If everything is going according to plan: then there are no mismatches.\n",
    "\n",
    "Assumption being made about the SNANA code here: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0c01fe94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " No Match Rows: \n",
      "\n",
      "Rows only in NOSCATTER (left_only):\n",
      "Empty DataFrame\n",
      "Columns: [FILENAME, MJD, BAND]\n",
      "Index: []\n",
      "\n",
      "Rows only in PLUSSCATTER (right_only):\n",
      "Empty DataFrame\n",
      "Columns: [FILENAME, MJD, BAND]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "compare_df = pd.merge(\n",
    "    nos_df,\n",
    "    plus_df,\n",
    "    on=[\"FILENAME\", \"MJD\", \"BAND\"],\n",
    "    suffixes=(\"_NO_S\", \"_PLUS_S\"),\n",
    "    how=\"outer\",\n",
    "    indicator=True  # Adds a column showing merge source\n",
    ")\n",
    "\n",
    "# --- Extract missing rows  NOSCATTER  PLUSSCATTER ---\n",
    "# note: left means the first DataFrame (nos_df)\n",
    "# note: right means the second DataFrame (plus_df)\n",
    "left_only = compare_df[compare_df[\"_merge\"] == \"left_only\"]\n",
    "right_only = compare_df[compare_df[\"_merge\"] == \"right_only\"]\n",
    "\n",
    "# --- Print results ---\n",
    "\n",
    "print(\" No Match Rows: \")\n",
    "\n",
    "print(\"\\nRows only in NOSCATTER (left_only):\")\n",
    "print(left_only[[\"FILENAME\", \"MJD\", \"BAND\"]])\n",
    "\n",
    "print(\"\\nRows only in PLUSSCATTER (right_only):\")\n",
    "print(right_only[[\"FILENAME\", \"MJD\", \"BAND\"]])\n",
    "\n",
    "compare_df.to_csv(\"compare_near_peak_rows.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d43c725",
   "metadata": {},
   "source": [
    "### Separating Our Merged Data into df that have individual g, r, i bands ###\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "390dd281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate into three DataFrames based on BAND\n",
    "merged_g_df = merged_df[merged_df[\"BAND\"].str.contains(\"LSST-g\")]\n",
    "merged_r_df = merged_df[merged_df[\"BAND\"].str.contains(\"LSST-r\")]\n",
    "merged_i_df = merged_df[merged_df[\"BAND\"].str.contains(\"LSST-i\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc728bf",
   "metadata": {},
   "source": [
    "### Converting FLUXCAL to Magnitudes\n",
    "\n",
    "We use the standard magnitude conversion:\n",
    "\n",
    "$\n",
    "m = 27.5 - 2.5 \\log_{10}(\\text{FLUXCAL})\n",
    "$\n",
    "\n",
    "Note: 27.5 is the zero point magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2f2b2f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[\"MAG_NO_S\"] = 27.5 - 2.5 * np.log10(merged_df[\"FLUXCAL_NO_S\"])\n",
    "merged_df[\"MAG_PLUS_S\"] = 27.5 - 2.5 * np.log10(merged_df[\"FLUXCAL_PLUS_S\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285d7efb",
   "metadata": {},
   "source": [
    "### RMS Scatter of Magnitudes\n",
    "\n",
    "$\\huge \\sigma_{\\text{scatter}} = \\sqrt{\\frac{1}{N}\\sum_{i=1}^{N}(m_{+,i} - m_{-,i})^2}$  \n",
    "\n",
    "Where:  \n",
    "- **$\\sigma_{\\text{scatter}}$** = RMS deviation between scatter and no-scatter magnitudes  \n",
    "- **$N$** = number of observations (data points)  \n",
    "- **$m_{+,i}$** = magnitude with scatter for the $i^{\\text{th}}$ observation  \n",
    "- **$m_{-,i}$** = magnitude without scatter for the $i^{\\text{th}}$ observation  \n",
    "\n",
    "**Conceptually:** We are measuring **how far the scatter simulation deviates from the no-scatter (baseline) magnitudes** on average.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "94147fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMS_LSST-g: 0.033295 (N = 10)\n",
      "RMS_LSST-r: 0.055185 (N = 63)\n",
      "RMS_LSST-i: 0.080266 (N = 132)\n"
     ]
    }
   ],
   "source": [
    "# --- Compute Δm = m_plus - m_no ---\n",
    "merged_df[\"DELTA_M\"] = merged_df[\"MAG_PLUS_S\"] - merged_df[\"MAG_NO_S\"]\n",
    "\n",
    "# --- Compute RMS per band ---\n",
    "rms_results = []\n",
    "\n",
    "for band in [\"LSST-g\", \"LSST-r\", \"LSST-i\"]:\n",
    "    band_mask = merged_df[\"BAND\"].str.contains(band)\n",
    "    band_data = merged_df.loc[band_mask, \"DELTA_M\"]\n",
    "    N = len(band_data)\n",
    "    rms = np.sqrt(np.mean(band_data**2))\n",
    "    rms_results.append((band, N, rms))\n",
    "    print(f\"RMS_{band}: {rms:.6f} (N = {N})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3297b19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
