{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "013da3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a9eade",
   "metadata": {},
   "source": [
    "### Modfication: Look for the  ###\n",
    "\n",
    "`PEAKMJD` is the Modified Julian Date (MJD) at which the supernova reaches peak brightness.\n",
    "It is listed in the header of each `.DAT` file.\n",
    "\n",
    "MJD is a  version of the Julian Date (JD) designed to use smaller numbers and to start the day at midnight instead of noon.\n",
    "\n",
    "The relationship is:\n",
    "\n",
    "$\n",
    "\\text{MJD} = \\text{JD} - 2400000.5\n",
    "$\n",
    "\n",
    "Julian Date (JD): Counts days continuously from January 1, 4713 BCE at 12:00 TT (Julian calendar).\n",
    "\n",
    "TT stands for **Terrestrial Time**, a modern astronomical time standard used for calcualtions.\n",
    "\n",
    "\n",
    "\n",
    "<h3><u>Lets look at a single file and this time:</u></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa71a497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PEAKMJD: 61800.129\n"
     ]
    }
   ],
   "source": [
    "file_path = \"/Users/pittsburghgraduatestudent/repos/pippin_learn/MC_BAYSN_NOSCATTER/MC_BAYSN_NOSCATTER_SN000001.DAT\"\n",
    "\n",
    "peak_mjd = None\n",
    "\n",
    "with open(file_path, \"r\") as f:\n",
    "    for line in f:\n",
    "        if \"PEAKMJD\" in line:\n",
    "            parts = line.strip().replace(\":\", \"\").split()\n",
    "            if \"PEAKMJD\" in parts:\n",
    "                peak_mjd = float(parts[parts.index(\"PEAKMJD\") + 1])\n",
    "                break\n",
    "\n",
    "print(f\"PEAKMJD: {peak_mjd}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c41b87",
   "metadata": {},
   "source": [
    "### Now lets look at that same single file and see if we can just filter out all the band measurements taht fall outside the +/- 7 days around the PEAKMJD ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "610aa3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PEAKMJD: 61800.129\n",
      "Number of near-peak rows: 9\n",
      "          MJD    BAND   FLUXCAL\n",
      "0  61794.0825  LSST-r  132721.0\n",
      "1  61795.0967  LSST-g  168515.0\n",
      "2  61795.1033  LSST-i  109874.0\n",
      "3  61795.1130  LSST-r  150376.0\n",
      "4  61800.1048  LSST-r  199163.0\n",
      "5  61800.1287  LSST-g  219159.0\n",
      "6  61802.0967  LSST-g  218760.0\n",
      "7  61802.1033  LSST-i  111339.0\n",
      "8  61802.1130  LSST-r  199301.0\n"
     ]
    }
   ],
   "source": [
    "# New data rows that will be stored once filtering is done.\n",
    "data_rows = []\n",
    "\n",
    "# Opens file and reads each line.\n",
    "# note: parts[1] is MJD, parts[2] is BAND, parts[4] is FLUXCAL\n",
    "# data_rows is a list of tuples (MJD, BAND, FLUXCAL)\n",
    "with open(file_path, \"r\") as f:\n",
    "    for line in f:\n",
    "        if line.startswith(\"OBS:\"):\n",
    "            parts = line.strip().split() #strips spaces, splits into python list.\n",
    "            mjd = float(parts[1])\n",
    "            band = parts[2]\n",
    "            fluxcal = float(parts[4])\n",
    "            data_rows.append((mjd, band, fluxcal))\n",
    "\n",
    "# --- Filter rows within ±7 days of PEAKMJD ---\n",
    "# note: row[0] is the first entry in tuple\n",
    "filtered_rows = []\n",
    "for row in data_rows:\n",
    "    mjd_value = row[0]\n",
    "    time_diff = abs(mjd_value - peak_mjd) \n",
    "    if time_diff <= 7:\n",
    "        filtered_rows.append(row)\n",
    "\n",
    "# --- Convert to a DataFrame ---\n",
    "df_filtered = pd.DataFrame(filtered_rows, columns=[\"MJD\", \"BAND\", \"FLUXCAL\"])\n",
    "\n",
    "print(f\"PEAKMJD: {peak_mjd}\")\n",
    "print(f\"Number of near-peak rows: {len(df_filtered)}\")\n",
    "print(df_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf074cd",
   "metadata": {},
   "source": [
    "### Now lets see if we can filter out anything that is within +/-7 days of the peak MJD ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01e65009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PEAKMJD: 61800.129\n",
      "Number of near-peak rows: 9\n",
      "          MJD    BAND FIELD   FLUXCAL  FLUXCALERR  PHOTFLAG  GAIN    ZPT  \\\n",
      "0  61794.0825  LSST-r   DDF  132721.0      5.2012      4096   1.0  36.73   \n",
      "1  61795.0967  LSST-g   DDF  168515.0      2.7386      6144   1.0  38.38   \n",
      "2  61795.1033  LSST-i   DDF  109874.0      1.5482      4096   1.0  39.16   \n",
      "3  61795.1130  LSST-r   DDF  150376.0      1.7502      4096   1.0  39.23   \n",
      "4  61800.1048  LSST-r   DDF  199163.0      6.4314      4096   1.0  36.71   \n",
      "5  61800.1287  LSST-g   DDF  219159.0      7.1556      4096   1.0  36.58   \n",
      "6  61802.0967  LSST-g   DDF  218760.0      3.1493      4096   1.0  38.36   \n",
      "7  61802.1033  LSST-i   DDF  111339.0      1.5759      4096   1.0  39.14   \n",
      "8  61802.1130  LSST-r   DDF  199301.0      2.0444      4096   1.0  39.20   \n",
      "\n",
      "    PSF  SKY_SIG  SIM_MAGOBS  \n",
      "0  1.60    243.8     14.6835  \n",
      "1  1.59    332.6     14.4213  \n",
      "2  1.38   1156.0     14.8982  \n",
      "3  1.49    786.2     14.5610  \n",
      "4  2.02    246.5     14.2556  \n",
      "5  2.03    148.5     14.1452  \n",
      "6  1.89    334.2     14.1539  \n",
      "7  1.73   1166.0     14.8767  \n",
      "8  2.13    790.1     14.2460  \n"
     ]
    }
   ],
   "source": [
    "# New data rows that will be stored once filtering is done.\n",
    "# Each entry will be a tuple in the same order as VARLIST:\n",
    "# (MJD, BAND, FIELD, FLUXCAL, FLUXCALERR, PHOTFLAG, GAIN, ZPT, PSF, SKY_SIG, SIM_MAGOBS)\n",
    "data_rows = []\n",
    "\n",
    "# Opens file and reads each line.\n",
    "# note: parts[1] is MJD, parts[2] is BAND, parts[3] is FIELD, parts[4] is FLUXCAL, etc.\n",
    "# note: MJD is measured in days. \n",
    "with open(file_path, \"r\") as f:\n",
    "    for line in f:\n",
    "        if line.startswith(\"OBS:\"):\n",
    "            parts = line.strip().split()  # strips spaces, splits into python list.\n",
    "\n",
    "            # Extract variables in the same order as VARLIST\n",
    "            mjd = float(parts[1])\n",
    "            band = parts[2]\n",
    "            field = parts[3]\n",
    "            fluxcal = float(parts[4])\n",
    "            fluxcalerr = float(parts[5])\n",
    "            photflag = int(parts[6])\n",
    "            gain = float(parts[7])\n",
    "            zpt = float(parts[8])\n",
    "            psf = float(parts[9])\n",
    "            sky_sig = float(parts[10])\n",
    "            sim_magobs = float(parts[11])\n",
    "\n",
    "            # Store everything as a list of tuples.\n",
    "            # Each tuple same as VARLIST order in og doc.\n",
    "            data_rows.append((\n",
    "                mjd, band, field, fluxcal, fluxcalerr,\n",
    "                photflag, gain, zpt, psf, sky_sig, sim_magobs\n",
    "            ))\n",
    "\n",
    "# --- Filter rows within ±7 days of PEAKMJD ---\n",
    "# note: row[0] is the first entry in tuple (MJD)\n",
    "filtered_rows = []\n",
    "for row in data_rows:\n",
    "    mjd_value = row[0]\n",
    "    time_diff = abs(mjd_value - peak_mjd)\n",
    "    if time_diff <= 7:\n",
    "        filtered_rows.append(row)\n",
    "\n",
    "# --- Convert to a DataFrame ---\n",
    "# Columns are labeled according to the VARLIST from the .DAT file\n",
    "df_filtered = pd.DataFrame(\n",
    "    filtered_rows,\n",
    "    columns=[\n",
    "        \"MJD\", \"BAND\", \"FIELD\", \"FLUXCAL\", \"FLUXCALERR\",\n",
    "        \"PHOTFLAG\", \"GAIN\", \"ZPT\", \"PSF\", \"SKY_SIG\", \"SIM_MAGOBS\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(f\"PEAKMJD: {peak_mjd}\")\n",
    "print(f\"Number of near-peak rows: {len(df_filtered)}\")\n",
    "print(df_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbffca81",
   "metadata": {},
   "source": [
    "### Now lets automate this to all the .dat files out there ###\n",
    "\n",
    "Step 1 would be to define a method that collects all the near peak rows from a given folder (i.e. MC_BAYSN_NOSCATTER or MC_BAYSN_PLUSSCATTER. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30dc04e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_near_peak_rows(folder_path):\n",
    "    \"\"\"\n",
    "    Collects all near-peak (±7 days) rows from all .DAT files in a folder.\n",
    "    Returns a DataFrame with all VARLIST columns + FILENAME.\n",
    "    \"\"\"\n",
    "\n",
    "    # Empty list to store all rows from all files\n",
    "    all_rows = []\n",
    "\n",
    "    # Loops through each file in the specified folder\n",
    "    # and builds path to each .DAT file\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".DAT\"):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "\n",
    "            # --- Extract PEAKMJD ---\n",
    "            peak_mjd = None # Emtpy variable to store PEAKMJD\n",
    "            with open(file_path, \"r\") as f:\n",
    "                for line in f:\n",
    "                    if \"PEAKMJD\" in line:\n",
    "                        parts = line.strip().replace(\":\", \"\").split()\n",
    "                        peak_mjd = float(parts[parts.index(\"PEAKMJD\") + 1])\n",
    "                        break\n",
    "\n",
    "            # --- Extract OBS rows and filter by ±7 days ---\n",
    "            with open(file_path, \"r\") as f:\n",
    "                for line in f:\n",
    "                    if line.startswith(\"OBS:\"):\n",
    "                        parts = line.strip().split()\n",
    "                        mjd = float(parts[1])\n",
    "                        band = parts[2]\n",
    "                        field = parts[3]\n",
    "                        fluxcal = float(parts[4])\n",
    "                        fluxcalerr = float(parts[5])\n",
    "                        photflag = int(parts[6])\n",
    "                        gain = float(parts[7])\n",
    "                        zpt = float(parts[8])\n",
    "                        psf = float(parts[9])\n",
    "                        sky_sig = float(parts[10])\n",
    "                        sim_magobs = float(parts[11])\n",
    "\n",
    "                        ## all_rows built up sequentially as we read each line.\n",
    "                        if abs(mjd - peak_mjd) <= 7:\n",
    "                            all_rows.append((\n",
    "                                filename, mjd, band, field, fluxcal, fluxcalerr,\n",
    "                                photflag, gain, zpt, psf, sky_sig, sim_magobs\n",
    "                            ))\n",
    "\n",
    "    return pd.DataFrame(\n",
    "        all_rows,\n",
    "        columns=[\n",
    "            \"FILENAME\", \"MJD\", \"BAND\", \"FIELD\", \"FLUXCAL\", \"FLUXCALERR\",\n",
    "            \"PHOTFLAG\", \"GAIN\", \"ZPT\", \"PSF\", \"SKY_SIG\", \"SIM_MAGOBS\"\n",
    "        ]\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d667e6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOSCATTER near-peak rows: 359\n",
      "PLUSSCATTER near-peak rows: 363\n",
      "NOSCATTER data saved to nos_near_peak_rows.csv\n",
      "PLUSSCATTER data saved to plus_near_peak_rows.csv\n"
     ]
    }
   ],
   "source": [
    "# --- STEP 1: Collect rows from both folders ---\n",
    "nos_folder = \"/Users/pittsburghgraduatestudent/repos/pippin_learn/MC_BAYSN_NOSCATTER\"\n",
    "plus_folder = \"/Users/pittsburghgraduatestudent/repos/pippin_learn/MC_BAYSN_PLUSSCATTER\"\n",
    "\n",
    "nos_df = collect_near_peak_rows(nos_folder)\n",
    "plus_df = collect_near_peak_rows(plus_folder)\n",
    "\n",
    "print(f\"NOSCATTER near-peak rows: {len(nos_df)}\")\n",
    "print(f\"PLUSSCATTER near-peak rows: {len(plus_df)}\")\n",
    "\n",
    "nos_df.to_csv(\"nos_near_peak_rows.csv\", index=False)\n",
    "plus_df.to_csv(\"plus_near_peak_rows.csv\", index=False)\n",
    "\n",
    "print(\"NOSCATTER data saved to nos_near_peak_rows.csv\")\n",
    "print(\"PLUSSCATTER data saved to plus_near_peak_rows.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e31a120",
   "metadata": {},
   "source": [
    "### Sorted by FILENAME and MJD to Better Explore the Code Using Human Eyes ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c490c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted NOSCATTER data saved to sorted_nos_near_peak_rows.csv\n",
      "Sorted PLUSSCATTER data saved to sorted_plus_near_peak_rows.csv\n"
     ]
    }
   ],
   "source": [
    "# Keep nos_df unchanged, create a sorted copy\n",
    "sorted_nos_df = nos_df.sort_values(by=[\"FILENAME\", \"MJD\"]).reset_index(drop=True)\n",
    "\n",
    "# Save sorted DataFrame to CSV\n",
    "sorted_nos_df.to_csv(\"sorted_nos_near_peak_rows.csv\", index=False)\n",
    "print(\"Sorted NOSCATTER data saved to sorted_nos_near_peak_rows.csv\")\n",
    "\n",
    "# Keep plus_df unchanged, create a sorted copy\n",
    "sorted_plus_df = plus_df.sort_values(by=[\"FILENAME\", \"MJD\"]).reset_index(drop=True)\n",
    "\n",
    "# Save sorted DataFrame to CSV\n",
    "sorted_plus_df.to_csv(\"sorted_plus_near_peak_rows.csv\", index=False)\n",
    "print(\"Sorted PLUSSCATTER data saved to sorted_plus_near_peak_rows.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ec01ea",
   "metadata": {},
   "source": [
    "### Found Out the cause of the Mismatch ###\n",
    "\n",
    "The individual FILENAME of each row, as part of the following .csv files contain `NOSCATTER` and `PLUSSCATTER` in them. Making it impossible to match any rows together even if matches exist. \n",
    "\n",
    "To solve this problem, I simply renamed the `FILENAME` of each .DAT file to contain only the SN identifier. \n",
    "\n",
    "For example: `MC_BAYSN_PLUSSCATTER_SN000011.DAT` -> `SN000011`\n",
    "\n",
    "This way when I try to Merge data files, I can use `FILENAME`, `MJD`, and `BAND` to precisely allign data together and ultimately: do computation on it. \n",
    "\n",
    "NOTE: this means that I have to keep careful track weather my .csv files are from the dataset that contained scatter vs. a data set that did not contain scatter. This is solved by the _NO_S and _PLUS_S header addendums in the output file: `merged_near_peak_rows.csv`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6cd306e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged data saved to merged_near_peak_rows.csv\n"
     ]
    }
   ],
   "source": [
    "# extracts the SN identifier from FILENAME\n",
    "# SN - literal text match\n",
    "# \\d+ - matches one or more digits after the SN\n",
    "# () - captures only this group and no other file name. \n",
    "\n",
    "nos_df[\"FILENAME\"] = nos_df[\"FILENAME\"].str.extract(r\"(SN\\d+)\")\n",
    "plus_df[\"FILENAME\"] = plus_df[\"FILENAME\"].str.extract(r\"(SN\\d+)\")\n",
    "\n",
    "merged_df = pd.merge(\n",
    "    nos_df,\n",
    "    plus_df,\n",
    "    on=[\"FILENAME\", \"MJD\", \"BAND\"],\n",
    "    suffixes=(\"_NO_S\", \"_PLUS_S\"),\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "merged_df.to_csv(\"merged_near_peak_rows.csv\", index=False)\n",
    "print(\"Merged data saved to merged_near_peak_rows.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155271f5",
   "metadata": {},
   "source": [
    "### Rows that Could not Be Matched ###\n",
    "\n",
    "Introducing scatter  ends up changing the PEAKMJD for individual .DAT files. This causes entreis in both NOSCATTER and PLUSSCATTER data files that are within +/- 7 days for indivudal data files but do not match entries in their counterpart as PEAKMDJDS will not cover the same ranges of MJD's between dat afiles. \n",
    "\n",
    "For an example of this take a look at The PEAKMJD entry in the `SN000016` .DAT files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c01fe94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " No Match Rows: \n",
      "\n",
      "Rows only in NOSCATTER (left_only):\n",
      "     FILENAME         MJD    BAND\n",
      "85   SN000016  60990.1218  LSST-r\n",
      "132  SN000025  61474.0242  LSST-g\n",
      "133  SN000025  61474.0308  LSST-i\n",
      "155  SN000038  60876.3473  LSST-g\n",
      "156  SN000038  60876.3550  LSST-i\n",
      "157  SN000038  60876.3647  LSST-r\n",
      "\n",
      "Rows only in PLUSSCATTER (right_only):\n",
      "     FILENAME         MJD    BAND\n",
      "124  SN000025  61456.0911  LSST-r\n",
      "125  SN000025  61456.1147  LSST-i\n",
      "158  SN000038  60886.2919  LSST-r\n",
      "159  SN000038  60886.3158  LSST-i\n",
      "160  SN000038  60890.2040  LSST-g\n",
      "161  SN000038  60890.2116  LSST-i\n",
      "162  SN000038  60890.2213  LSST-r\n",
      "326  SN000086  61379.1589  LSST-g\n",
      "327  SN000086  61379.1655  LSST-i\n",
      "328  SN000086  61379.1752  LSST-r\n"
     ]
    }
   ],
   "source": [
    "compare_df = pd.merge(\n",
    "    nos_df,\n",
    "    plus_df,\n",
    "    on=[\"FILENAME\", \"MJD\", \"BAND\"],\n",
    "    suffixes=(\"_NO_S\", \"_PLUS_S\"),\n",
    "    how=\"outer\",\n",
    "    indicator=True  # Adds a column showing merge source\n",
    ")\n",
    "\n",
    "# --- Extract missing rows  NOSCATTER  PLUSSCATTER ---\n",
    "# note: left means the first DataFrame (nos_df)\n",
    "# note: right means the second DataFrame (plus_df)\n",
    "left_only = compare_df[compare_df[\"_merge\"] == \"left_only\"]\n",
    "right_only = compare_df[compare_df[\"_merge\"] == \"right_only\"]\n",
    "\n",
    "# --- Print results ---\n",
    "\n",
    "print(\" No Match Rows: \")\n",
    "\n",
    "print(\"\\nRows only in NOSCATTER (left_only):\")\n",
    "print(left_only[[\"FILENAME\", \"MJD\", \"BAND\"]])\n",
    "\n",
    "print(\"\\nRows only in PLUSSCATTER (right_only):\")\n",
    "print(right_only[[\"FILENAME\", \"MJD\", \"BAND\"]])\n",
    "\n",
    "compare_df.to_csv(\"compare_near_peak_rows.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d43c725",
   "metadata": {},
   "source": [
    "### Separating Our Merged Data into df that have individual g, r, i bands ###\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "390dd281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate into three DataFrames based on BAND\n",
    "merged_g_df = merged_df[merged_df[\"BAND\"].str.contains(\"LSST-g\")]\n",
    "merged_r_df = merged_df[merged_df[\"BAND\"].str.contains(\"LSST-r\")]\n",
    "merged_i_df = merged_df[merged_df[\"BAND\"].str.contains(\"LSST-i\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc728bf",
   "metadata": {},
   "source": [
    "### Converting FLUXCAL to Magnitudes\n",
    "\n",
    "We use the standard magnitude conversion:\n",
    "\n",
    "$\n",
    "m = 27.5 - 2.5 \\log_{10}(\\text{FLUXCAL})\n",
    "$\n",
    "\n",
    "Note: 27.5 is the zero point magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f2b2f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[\"MAG_NO_S\"] = 27.5 - 2.5 * np.log10(merged_df[\"FLUXCAL_NO_S\"])\n",
    "merged_df[\"MAG_PLUS_S\"] = 27.5 - 2.5 * np.log10(merged_df[\"FLUXCAL_PLUS_S\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285d7efb",
   "metadata": {},
   "source": [
    "### RMS Scatter of Magnitudes\n",
    "\n",
    "$\\huge \\sigma_{\\text{scatter}} = \\sqrt{\\frac{1}{N}\\sum_{i=1}^{N}(m_{+,i} - m_{-,i})^2}$  \n",
    "\n",
    "Where:  \n",
    "- **$\\sigma_{\\text{scatter}}$** = RMS deviation between scatter and no-scatter magnitudes  \n",
    "- **$N$** = number of observations (data points)  \n",
    "- **$m_{+,i}$** = magnitude with scatter for the $i^{\\text{th}}$ observation  \n",
    "- **$m_{-,i}$** = magnitude without scatter for the $i^{\\text{th}}$ observation  \n",
    "\n",
    "**Conceptually:** We are measuring **how far the scatter simulation deviates from the no-scatter (baseline) magnitudes** on average.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94147fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RMS Results:\n",
      "RMS_LSST-g: 0.130852 (N = 83)\n",
      "RMS_LSST-r: 0.123455 (N = 133)\n",
      "RMS_LSST-i: 0.121236 (N = 137)\n"
     ]
    }
   ],
   "source": [
    "# --- Compute Δm = m_plus - m_no ---\n",
    "merged_df[\"DELTA_M\"] = merged_df[\"MAG_PLUS_S\"] - merged_df[\"MAG_NO_S\"]\n",
    "\n",
    "# --- Compute RMS per band ---\n",
    "rms_results = []\n",
    "\n",
    "for band in [\"LSST-g\", \"LSST-r\", \"LSST-i\"]:\n",
    "    band_mask = merged_df[\"BAND\"].str.contains(band)\n",
    "    band_data = merged_df.loc[band_mask, \"DELTA_M\"]\n",
    "    N = len(band_data)\n",
    "    rms = np.sqrt(np.mean(band_data**2))\n",
    "    rms_results.append((band, N, rms))\n",
    "\n",
    "# Print RMS results\n",
    "print(\"\\nRMS Results:\")\n",
    "for band, N, rms in rms_results:\n",
    "    print(f\"RMS_{band}: {rms:.6f} (N = {N})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3297b19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
